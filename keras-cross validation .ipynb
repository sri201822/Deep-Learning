{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation can be used for a variety of purposes in predictive modeling. These include:\n",
    "\n",
    "Generating out-of-sample predictions from a neural network\n",
    "Estimate a good number of epochs to train a neural network for (early stopping)\n",
    "Evaluate the effectiveness of certain hyperparameters, such as activation functions, neuron counts, and layer counts\n",
    "Cross-validation uses a number of folds, and multiple models, to provide each segment of data a chance to serve as both the validation and training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression: we use KFold cross validation.\n",
    "Classification: we use stratifiedKFold cross validation as balance of classes is important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job</th>\n",
       "      <th>area</th>\n",
       "      <th>income</th>\n",
       "      <th>aspect</th>\n",
       "      <th>subscriptions</th>\n",
       "      <th>dist_healthy</th>\n",
       "      <th>save_rate</th>\n",
       "      <th>dist_unhealthy</th>\n",
       "      <th>age</th>\n",
       "      <th>pop_dense</th>\n",
       "      <th>retail_dense</th>\n",
       "      <th>crime</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>vv</td>\n",
       "      <td>c</td>\n",
       "      <td>50876.0</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>9.017895</td>\n",
       "      <td>35</td>\n",
       "      <td>11.738935</td>\n",
       "      <td>49</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>kd</td>\n",
       "      <td>c</td>\n",
       "      <td>60369.0</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>2</td>\n",
       "      <td>7.766643</td>\n",
       "      <td>59</td>\n",
       "      <td>6.805396</td>\n",
       "      <td>51</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.342520</td>\n",
       "      <td>0.400809</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>pe</td>\n",
       "      <td>c</td>\n",
       "      <td>55126.0</td>\n",
       "      <td>34.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>6</td>\n",
       "      <td>13.671772</td>\n",
       "      <td>44</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.207723</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>c</td>\n",
       "      <td>51690.0</td>\n",
       "      <td>15.808333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.372942</td>\n",
       "      <td>16</td>\n",
       "      <td>4.333286</td>\n",
       "      <td>50</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.361216</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>kl</td>\n",
       "      <td>d</td>\n",
       "      <td>28347.0</td>\n",
       "      <td>40.941667</td>\n",
       "      <td>3</td>\n",
       "      <td>3.822477</td>\n",
       "      <td>20</td>\n",
       "      <td>5.967121</td>\n",
       "      <td>38</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.068033</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>1996</td>\n",
       "      <td>vv</td>\n",
       "      <td>c</td>\n",
       "      <td>51017.0</td>\n",
       "      <td>38.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>34</td>\n",
       "      <td>14.013489</td>\n",
       "      <td>41</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.104838</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>1997</td>\n",
       "      <td>kl</td>\n",
       "      <td>d</td>\n",
       "      <td>26576.0</td>\n",
       "      <td>33.358333</td>\n",
       "      <td>2</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>20</td>\n",
       "      <td>8.380497</td>\n",
       "      <td>38</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.877953</td>\n",
       "      <td>0.063851</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>kl</td>\n",
       "      <td>d</td>\n",
       "      <td>28595.0</td>\n",
       "      <td>39.425000</td>\n",
       "      <td>3</td>\n",
       "      <td>7.168218</td>\n",
       "      <td>99</td>\n",
       "      <td>4.626950</td>\n",
       "      <td>36</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.098703</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>1999</td>\n",
       "      <td>qp</td>\n",
       "      <td>c</td>\n",
       "      <td>67949.0</td>\n",
       "      <td>5.733333</td>\n",
       "      <td>0</td>\n",
       "      <td>8.936292</td>\n",
       "      <td>26</td>\n",
       "      <td>3.281439</td>\n",
       "      <td>46</td>\n",
       "      <td>0.909449</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>0.117803</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>pe</td>\n",
       "      <td>c</td>\n",
       "      <td>61467.0</td>\n",
       "      <td>16.891667</td>\n",
       "      <td>0</td>\n",
       "      <td>4.312097</td>\n",
       "      <td>8</td>\n",
       "      <td>9.405648</td>\n",
       "      <td>48</td>\n",
       "      <td>0.925197</td>\n",
       "      <td>0.539370</td>\n",
       "      <td>0.451973</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id job area   income     aspect  subscriptions  dist_healthy  \\\n",
       "0        1  vv    c  50876.0  13.100000              1      9.017895   \n",
       "1        2  kd    c  60369.0  18.625000              2      7.766643   \n",
       "2        3  pe    c  55126.0  34.766667              1      3.632069   \n",
       "3        4  11    c  51690.0  15.808333              1      5.372942   \n",
       "4        5  kl    d  28347.0  40.941667              3      3.822477   \n",
       "...    ...  ..  ...      ...        ...            ...           ...   \n",
       "1995  1996  vv    c  51017.0  38.233333              1      5.454545   \n",
       "1996  1997  kl    d  26576.0  33.358333              2      3.632069   \n",
       "1997  1998  kl    d  28595.0  39.425000              3      7.168218   \n",
       "1998  1999  qp    c  67949.0   5.733333              0      8.936292   \n",
       "1999  2000  pe    c  61467.0  16.891667              0      4.312097   \n",
       "\n",
       "      save_rate  dist_unhealthy  age  pop_dense  retail_dense     crime  \\\n",
       "0            35       11.738935   49   0.885827      0.492126  0.071100   \n",
       "1            59        6.805396   51   0.874016      0.342520  0.400809   \n",
       "2             6       13.671772   44   0.944882      0.724409  0.207723   \n",
       "3            16        4.333286   50   0.889764      0.444882  0.361216   \n",
       "4            20        5.967121   38   0.744094      0.661417  0.068033   \n",
       "...         ...             ...  ...        ...           ...       ...   \n",
       "1995         34       14.013489   41   0.881890      0.744094  0.104838   \n",
       "1996         20        8.380497   38   0.944882      0.877953  0.063851   \n",
       "1997         99        4.626950   36   0.759843      0.744094  0.098703   \n",
       "1998         26        3.281439   46   0.909449      0.598425  0.117803   \n",
       "1999          8        9.405648   48   0.925197      0.539370  0.451973   \n",
       "\n",
       "     product  \n",
       "0          b  \n",
       "1          c  \n",
       "2          b  \n",
       "3          b  \n",
       "4          a  \n",
       "...      ...  \n",
       "1995       b  \n",
       "1996       a  \n",
       "1997       f  \n",
       "1998       c  \n",
       "1999       c  \n",
       "\n",
       "[2000 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df,pd.get_dummies(df['job'],prefix='job')],axis=1)\n",
    "df=pd.concat([df,pd.get_dummies(df['area'],prefix='area')],axis=1)\n",
    "df=pd.concat([df,pd.get_dummies(df['product'],prefix='prod')],axis=1)\n",
    "df=df.drop(['job','area','product'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'income', 'aspect', 'subscriptions', 'dist_healthy', 'save_rate',\n",
       "       'dist_unhealthy', 'age', 'pop_dense', 'retail_dense', 'crime', 'job_11',\n",
       "       'job_al', 'job_am', 'job_ax', 'job_bf', 'job_by', 'job_cv', 'job_de',\n",
       "       'job_dz', 'job_e2', 'job_f8', 'job_gj', 'job_gv', 'job_kd', 'job_ke',\n",
       "       'job_kl', 'job_kp', 'job_ks', 'job_kw', 'job_mm', 'job_nb', 'job_nn',\n",
       "       'job_ob', 'job_pe', 'job_po', 'job_pq', 'job_pz', 'job_qp', 'job_qw',\n",
       "       'job_rn', 'job_sa', 'job_vv', 'job_zz', 'area_a', 'area_b', 'area_c',\n",
       "       'area_d', 'prod_a', 'prod_b', 'prod_c', 'prod_d', 'prod_e', 'prod_f',\n",
       "       'prod_g'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "income            59\n",
       "aspect             0\n",
       "subscriptions      0\n",
       "dist_healthy       0\n",
       "save_rate          0\n",
       "dist_unhealthy     0\n",
       "age                0\n",
       "pop_dense          0\n",
       "retail_dense       0\n",
       "crime              0\n",
       "job_11             0\n",
       "job_al             0\n",
       "job_am             0\n",
       "job_ax             0\n",
       "job_bf             0\n",
       "job_by             0\n",
       "job_cv             0\n",
       "job_de             0\n",
       "job_dz             0\n",
       "job_e2             0\n",
       "job_f8             0\n",
       "job_gj             0\n",
       "job_gv             0\n",
       "job_kd             0\n",
       "job_ke             0\n",
       "job_kl             0\n",
       "job_kp             0\n",
       "job_ks             0\n",
       "job_kw             0\n",
       "job_mm             0\n",
       "job_nb             0\n",
       "job_nn             0\n",
       "job_ob             0\n",
       "job_pe             0\n",
       "job_po             0\n",
       "job_pq             0\n",
       "job_pz             0\n",
       "job_qp             0\n",
       "job_qw             0\n",
       "job_rn             0\n",
       "job_sa             0\n",
       "job_vv             0\n",
       "job_zz             0\n",
       "area_a             0\n",
       "area_b             0\n",
       "area_c             0\n",
       "area_d             0\n",
       "prod_a             0\n",
       "prod_b             0\n",
       "prod_c             0\n",
       "prod_d             0\n",
       "prod_e             0\n",
       "prod_f             0\n",
       "prod_g             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2d301c0abc8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(y='income',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1941.000000\n",
       "mean     56924.861927\n",
       "std      10188.938399\n",
       "min      19846.000000\n",
       "25%      51336.000000\n",
       "50%      58633.000000\n",
       "75%      64407.000000\n",
       "max      88671.000000\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['income'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income']=df['income'].fillna(df['income'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income']=zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns=df.columns.drop(['age','id'])\n",
    "x=df[x_columns].values\n",
    "y=df['age'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (RMSE): 0.6285728658861756\n",
      "Fold #2\n",
      "Fold score (RMSE): 0.6135405020361389\n",
      "Fold #3\n",
      "Fold score (RMSE): 0.6752010060827243\n",
      "Fold #4\n",
      "Fold score (RMSE): 0.45641196683512303\n",
      "Fold #5\n",
      "Fold score (RMSE): 0.9625404239212146\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "# Cross-Validate\n",
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "\n",
    "fold = 0\n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),verbose=0,epochs=500)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred)    \n",
    "\n",
    "    # Measure this fold's RMSE\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(f\"Fold score (RMSE): {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final, out of sample score (RMSE): 0.6873468040421774\n"
     ]
    }
   ],
   "source": [
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print(f\"Final, out of sample score (RMSE): {score}\")    \n",
    "    \n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>income</th>\n",
       "      <th>aspect</th>\n",
       "      <th>subscriptions</th>\n",
       "      <th>dist_healthy</th>\n",
       "      <th>save_rate</th>\n",
       "      <th>dist_unhealthy</th>\n",
       "      <th>age</th>\n",
       "      <th>pop_dense</th>\n",
       "      <th>retail_dense</th>\n",
       "      <th>...</th>\n",
       "      <th>area_d</th>\n",
       "      <th>prod_a</th>\n",
       "      <th>prod_b</th>\n",
       "      <th>prod_c</th>\n",
       "      <th>prod_d</th>\n",
       "      <th>prod_e</th>\n",
       "      <th>prod_f</th>\n",
       "      <th>prod_g</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.607550</td>\n",
       "      <td>-0.664918</td>\n",
       "      <td>-0.208449</td>\n",
       "      <td>9.017895</td>\n",
       "      <td>-0.215764</td>\n",
       "      <td>11.738935</td>\n",
       "      <td>49</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>47.911461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.338053</td>\n",
       "      <td>-0.207748</td>\n",
       "      <td>0.839031</td>\n",
       "      <td>7.766643</td>\n",
       "      <td>0.196869</td>\n",
       "      <td>6.805396</td>\n",
       "      <td>51</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.342520</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>49.504757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.184205</td>\n",
       "      <td>1.127906</td>\n",
       "      <td>-0.208449</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>-0.714362</td>\n",
       "      <td>13.671772</td>\n",
       "      <td>44</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>45.086365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.526467</td>\n",
       "      <td>-0.440815</td>\n",
       "      <td>-0.208449</td>\n",
       "      <td>5.372942</td>\n",
       "      <td>-0.542432</td>\n",
       "      <td>4.333286</td>\n",
       "      <td>50</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>48.790100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.851675</td>\n",
       "      <td>1.638861</td>\n",
       "      <td>1.886511</td>\n",
       "      <td>3.822477</td>\n",
       "      <td>-0.473660</td>\n",
       "      <td>5.967121</td>\n",
       "      <td>38</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>36.685543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>1996</td>\n",
       "      <td>-0.593504</td>\n",
       "      <td>1.414758</td>\n",
       "      <td>-0.208449</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>-0.232957</td>\n",
       "      <td>14.013489</td>\n",
       "      <td>41</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>48.478546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>1997</td>\n",
       "      <td>-3.028085</td>\n",
       "      <td>1.011372</td>\n",
       "      <td>0.839031</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>-0.473660</td>\n",
       "      <td>8.380497</td>\n",
       "      <td>38</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.877953</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>46.323975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>-2.826971</td>\n",
       "      <td>1.513363</td>\n",
       "      <td>1.886511</td>\n",
       "      <td>7.168218</td>\n",
       "      <td>0.884591</td>\n",
       "      <td>4.626950</td>\n",
       "      <td>36</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>49.099472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.093101</td>\n",
       "      <td>-1.274478</td>\n",
       "      <td>-1.255928</td>\n",
       "      <td>8.936292</td>\n",
       "      <td>-0.370502</td>\n",
       "      <td>3.281439</td>\n",
       "      <td>46</td>\n",
       "      <td>0.909449</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>43.544144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.447425</td>\n",
       "      <td>-0.351174</td>\n",
       "      <td>-1.255928</td>\n",
       "      <td>4.312097</td>\n",
       "      <td>-0.679976</td>\n",
       "      <td>9.405648</td>\n",
       "      <td>48</td>\n",
       "      <td>0.925197</td>\n",
       "      <td>0.539370</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>37.965225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    income    aspect  subscriptions  dist_healthy  save_rate  \\\n",
       "0        1 -0.607550 -0.664918      -0.208449      9.017895  -0.215764   \n",
       "1        2  0.338053 -0.207748       0.839031      7.766643   0.196869   \n",
       "2        3 -0.184205  1.127906      -0.208449      3.632069  -0.714362   \n",
       "3        4 -0.526467 -0.440815      -0.208449      5.372942  -0.542432   \n",
       "4        5 -2.851675  1.638861       1.886511      3.822477  -0.473660   \n",
       "...    ...       ...       ...            ...           ...        ...   \n",
       "1995  1996 -0.593504  1.414758      -0.208449      5.454545  -0.232957   \n",
       "1996  1997 -3.028085  1.011372       0.839031      3.632069  -0.473660   \n",
       "1997  1998 -2.826971  1.513363       1.886511      7.168218   0.884591   \n",
       "1998  1999  1.093101 -1.274478      -1.255928      8.936292  -0.370502   \n",
       "1999  2000  0.447425 -0.351174      -1.255928      4.312097  -0.679976   \n",
       "\n",
       "      dist_unhealthy  age  pop_dense  retail_dense  ...  area_d  prod_a  \\\n",
       "0          11.738935   49   0.885827      0.492126  ...       0       0   \n",
       "1           6.805396   51   0.874016      0.342520  ...       0       0   \n",
       "2          13.671772   44   0.944882      0.724409  ...       0       0   \n",
       "3           4.333286   50   0.889764      0.444882  ...       0       0   \n",
       "4           5.967121   38   0.744094      0.661417  ...       1       1   \n",
       "...              ...  ...        ...           ...  ...     ...     ...   \n",
       "1995       14.013489   41   0.881890      0.744094  ...       0       0   \n",
       "1996        8.380497   38   0.944882      0.877953  ...       1       1   \n",
       "1997        4.626950   36   0.759843      0.744094  ...       1       0   \n",
       "1998        3.281439   46   0.909449      0.598425  ...       0       0   \n",
       "1999        9.405648   48   0.925197      0.539370  ...       0       0   \n",
       "\n",
       "      prod_b  prod_c  prod_d  prod_e  prod_f  prod_g   0          0  \n",
       "0          1       0       0       0       0       0  47  47.911461  \n",
       "1          0       1       0       0       0       0  49  49.504757  \n",
       "2          1       0       0       0       0       0  46  45.086365  \n",
       "3          1       0       0       0       0       0  49  48.790100  \n",
       "4          0       0       0       0       0       0  37  36.685543  \n",
       "...      ...     ...     ...     ...     ...     ...  ..        ...  \n",
       "1995       1       0       0       0       0       0  49  48.478546  \n",
       "1996       0       0       0       0       0       0  47  46.323975  \n",
       "1997       0       0       0       0       1       0  49  49.099472  \n",
       "1998       0       1       0       0       0       0  44  43.544144  \n",
       "1999       0       1       0       0       0       0  38  37.965225  \n",
       "\n",
       "[2000 rows x 57 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oosDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (accuracy): 0.6716417910447762\n",
      "Fold #2\n",
      "Fold score (accuracy): 0.6666666666666666\n",
      "Fold #3\n",
      "Fold score (accuracy): 0.7182044887780549\n",
      "Fold #4\n",
      "Fold score (accuracy): 0.6658291457286433\n",
      "Fold #5\n",
      "Fold score (accuracy): 0.6775818639798489\n",
      "Final score (accuracy): 0.68\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "# np.argmax(pred,axis=1)\n",
    "# Cross-validate\n",
    "kf = StratifiedKFold(5, shuffle=True, random_state=42) # Use for StratifiedKFold classification\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(x,df['product']): # Must specify y for StratifiedKFold \n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "    model.add(Dense(25, activation='relu')) # Hidden 2\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),verbose=0,epochs=500)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    pred = np.argmax(pred,axis=1) # raw probabilities to chosen class (highest probability)\n",
    "    oos_pred.append(pred)  \n",
    "\n",
    "    # Measure this fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) # For accuracy calculation\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_y_compare = np.argmax(oos_y,axis=1) # For accuracy calculation\n",
    "\n",
    "score = metrics.accuracy_score(oos_y_compare, oos_pred)\n",
    "print(f\"Final score (accuracy): {score}\")    \n",
    "    \n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>income</th>\n",
       "      <th>aspect</th>\n",
       "      <th>subscriptions</th>\n",
       "      <th>dist_healthy</th>\n",
       "      <th>save_rate</th>\n",
       "      <th>dist_unhealthy</th>\n",
       "      <th>age</th>\n",
       "      <th>pop_dense</th>\n",
       "      <th>retail_dense</th>\n",
       "      <th>...</th>\n",
       "      <th>area_c</th>\n",
       "      <th>area_d</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.607550</td>\n",
       "      <td>-0.664918</td>\n",
       "      <td>-0.208449</td>\n",
       "      <td>9.017895</td>\n",
       "      <td>-0.215764</td>\n",
       "      <td>11.738935</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.338053</td>\n",
       "      <td>-0.207748</td>\n",
       "      <td>0.839031</td>\n",
       "      <td>7.766643</td>\n",
       "      <td>0.196869</td>\n",
       "      <td>6.805396</td>\n",
       "      <td>1.394432</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.342520</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.184205</td>\n",
       "      <td>1.127906</td>\n",
       "      <td>-0.208449</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>-0.714362</td>\n",
       "      <td>13.671772</td>\n",
       "      <td>-0.495957</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.526467</td>\n",
       "      <td>-0.440815</td>\n",
       "      <td>-0.208449</td>\n",
       "      <td>5.372942</td>\n",
       "      <td>-0.542432</td>\n",
       "      <td>4.333286</td>\n",
       "      <td>1.124377</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.851675</td>\n",
       "      <td>1.638861</td>\n",
       "      <td>1.886511</td>\n",
       "      <td>3.822477</td>\n",
       "      <td>-0.473660</td>\n",
       "      <td>5.967121</td>\n",
       "      <td>-2.116291</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>1996</td>\n",
       "      <td>-0.593504</td>\n",
       "      <td>1.414758</td>\n",
       "      <td>-0.208449</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>-0.232957</td>\n",
       "      <td>14.013489</td>\n",
       "      <td>-1.306124</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>1997</td>\n",
       "      <td>-3.028085</td>\n",
       "      <td>1.011372</td>\n",
       "      <td>0.839031</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>-0.473660</td>\n",
       "      <td>8.380497</td>\n",
       "      <td>-2.116291</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.877953</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>-2.826971</td>\n",
       "      <td>1.513363</td>\n",
       "      <td>1.886511</td>\n",
       "      <td>7.168218</td>\n",
       "      <td>0.884591</td>\n",
       "      <td>4.626950</td>\n",
       "      <td>-2.656402</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.093101</td>\n",
       "      <td>-1.274478</td>\n",
       "      <td>-1.255928</td>\n",
       "      <td>8.936292</td>\n",
       "      <td>-0.370502</td>\n",
       "      <td>3.281439</td>\n",
       "      <td>0.044154</td>\n",
       "      <td>0.909449</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.447425</td>\n",
       "      <td>-0.351174</td>\n",
       "      <td>-1.255928</td>\n",
       "      <td>4.312097</td>\n",
       "      <td>-0.679976</td>\n",
       "      <td>9.405648</td>\n",
       "      <td>0.584265</td>\n",
       "      <td>0.925197</td>\n",
       "      <td>0.539370</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    income    aspect  subscriptions  dist_healthy  save_rate  \\\n",
       "0        1 -0.607550 -0.664918      -0.208449      9.017895  -0.215764   \n",
       "1        2  0.338053 -0.207748       0.839031      7.766643   0.196869   \n",
       "2        3 -0.184205  1.127906      -0.208449      3.632069  -0.714362   \n",
       "3        4 -0.526467 -0.440815      -0.208449      5.372942  -0.542432   \n",
       "4        5 -2.851675  1.638861       1.886511      3.822477  -0.473660   \n",
       "...    ...       ...       ...            ...           ...        ...   \n",
       "1995  1996 -0.593504  1.414758      -0.208449      5.454545  -0.232957   \n",
       "1996  1997 -3.028085  1.011372       0.839031      3.632069  -0.473660   \n",
       "1997  1998 -2.826971  1.513363       1.886511      7.168218   0.884591   \n",
       "1998  1999  1.093101 -1.274478      -1.255928      8.936292  -0.370502   \n",
       "1999  2000  0.447425 -0.351174      -1.255928      4.312097  -0.679976   \n",
       "\n",
       "      dist_unhealthy       age  pop_dense  retail_dense  ...  area_c area_d  \\\n",
       "0          11.738935  0.854321   0.885827      0.492126  ...       1      0   \n",
       "1           6.805396  1.394432   0.874016      0.342520  ...       1      0   \n",
       "2          13.671772 -0.495957   0.944882      0.724409  ...       1      0   \n",
       "3           4.333286  1.124377   0.889764      0.444882  ...       1      0   \n",
       "4           5.967121 -2.116291   0.744094      0.661417  ...       0      1   \n",
       "...              ...       ...        ...           ...  ...     ...    ...   \n",
       "1995       14.013489 -1.306124   0.881890      0.744094  ...       1      0   \n",
       "1996        8.380497 -2.116291   0.944882      0.877953  ...       0      1   \n",
       "1997        4.626950 -2.656402   0.759843      0.744094  ...       0      1   \n",
       "1998        3.281439  0.044154   0.909449      0.598425  ...       1      0   \n",
       "1999        9.405648  0.584265   0.925197      0.539370  ...       1      0   \n",
       "\n",
       "      0  1  2  3  4  5  6  0  \n",
       "0     0  1  0  0  0  0  0  1  \n",
       "1     0  1  0  0  0  0  0  1  \n",
       "2     0  0  1  0  0  0  0  2  \n",
       "3     0  1  0  0  0  0  0  1  \n",
       "4     0  1  0  0  0  0  0  1  \n",
       "...  .. .. .. .. .. .. .. ..  \n",
       "1995  0  1  0  0  0  0  0  1  \n",
       "1996  0  1  0  0  0  0  0  2  \n",
       "1997  0  0  0  0  0  1  0  5  \n",
       "1998  0  1  0  0  0  0  0  1  \n",
       "1999  1  0  0  0  0  0  0  0  \n",
       "\n",
       "[2000 rows x 57 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oosDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation and hold out for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for product\n",
    "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
    "df.drop('product', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('age').drop('id')\n",
    "x = df[x_columns].values\n",
    "y = df['age'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (RMSE): 0.7274323394809464\n",
      "Fold #2\n",
      "Fold score (RMSE): 0.5613542921884157\n",
      "Fold #3\n",
      "Fold score (RMSE): 0.6373533418422356\n",
      "Fold #4\n",
      "Fold score (RMSE): 0.6277793165849047\n",
      "Fold #5\n",
      "Fold score (RMSE): 24.180366071273887\n",
      "\n",
      "Cross-validated score (RMSE): 10.828986157008272\n",
      "Holdout score (RMSE): 24.366053464300524\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Keep a 10% holdout\n",
    "x_main, x_holdout, y_main, y_holdout = train_test_split(    \n",
    "    x, y, test_size=0.10) \n",
    "\n",
    "\n",
    "# Cross-validate\n",
    "kf = KFold(5)\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "for train, test in kf.split(x_main):        \n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x_main[train]\n",
    "    y_train = y_main[train]\n",
    "    x_test = x_main[test]\n",
    "    y_test = y_main[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),verbose=0,epochs=500)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred) \n",
    "\n",
    "    # Measure accuracy\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(f\"Fold score (RMSE): {score}\")\n",
    "\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print()\n",
    "print(f\"Cross-validated score (RMSE): {score}\")    \n",
    "    \n",
    "# Write the cross-validated prediction (from the last neural network)\n",
    "holdout_pred = model.predict(x_holdout)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(holdout_pred,y_holdout))\n",
    "print(f\"Holdout score (RMSE): {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation and hold out for classification (Issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Keep a 10% holdout\n",
    "x_main, x_holdout, y_main, y_holdout = train_test_split(    \n",
    "    x, y, test_size=0.10) \n",
    "\n",
    "# Cross-validate\n",
    "kf = StratifiedKFold(5, shuffle=True, random_state=42) # Use for StratifiedKFold classification\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(x_main,df['product'].loc[0:1799]): # Must specify y for StratifiedKFold \n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x_main[train]\n",
    "    y_train = y_main[train]\n",
    "    x_test = x_main[test]\n",
    "    y_test = y_main[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "    model.add(Dense(25, activation='relu')) # Hidden 2\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),verbose=0,epochs=500)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    pred = np.argmax(pred,axis=1) # raw probabilities to chosen class (highest probability)\n",
    "    oos_pred.append(pred)  \n",
    "\n",
    "    # Measure this fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) # For accuracy calculation\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_y_compare = np.argmax(oos_y,axis=1) # For accuracy calculation\n",
    "\n",
    "score = metrics.accuracy_score(oos_y_compare, oos_pred)\n",
    "print(f\"Final score (accuracy): {score}\")    \n",
    "    \n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>income</th>\n",
       "      <th>aspect</th>\n",
       "      <th>subscriptions</th>\n",
       "      <th>dist_healthy</th>\n",
       "      <th>save_rate</th>\n",
       "      <th>dist_unhealthy</th>\n",
       "      <th>age</th>\n",
       "      <th>pop_dense</th>\n",
       "      <th>retail_dense</th>\n",
       "      <th>...</th>\n",
       "      <th>area_c</th>\n",
       "      <th>area_d</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.607550</td>\n",
       "      <td>-0.664918</td>\n",
       "      <td>-0.208449</td>\n",
       "      <td>9.017895</td>\n",
       "      <td>-0.215764</td>\n",
       "      <td>11.738935</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.338053</td>\n",
       "      <td>-0.207748</td>\n",
       "      <td>0.839031</td>\n",
       "      <td>7.766643</td>\n",
       "      <td>0.196869</td>\n",
       "      <td>6.805396</td>\n",
       "      <td>1.394432</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.342520</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.184205</td>\n",
       "      <td>1.127906</td>\n",
       "      <td>-0.208449</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>-0.714362</td>\n",
       "      <td>13.671772</td>\n",
       "      <td>-0.495957</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.526467</td>\n",
       "      <td>-0.440815</td>\n",
       "      <td>-0.208449</td>\n",
       "      <td>5.372942</td>\n",
       "      <td>-0.542432</td>\n",
       "      <td>4.333286</td>\n",
       "      <td>1.124377</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.851675</td>\n",
       "      <td>1.638861</td>\n",
       "      <td>1.886511</td>\n",
       "      <td>3.822477</td>\n",
       "      <td>-0.473660</td>\n",
       "      <td>5.967121</td>\n",
       "      <td>-2.116291</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>1996</td>\n",
       "      <td>-0.593504</td>\n",
       "      <td>1.414758</td>\n",
       "      <td>-0.208449</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>-0.232957</td>\n",
       "      <td>14.013489</td>\n",
       "      <td>-1.306124</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>1997</td>\n",
       "      <td>-3.028085</td>\n",
       "      <td>1.011372</td>\n",
       "      <td>0.839031</td>\n",
       "      <td>3.632069</td>\n",
       "      <td>-0.473660</td>\n",
       "      <td>8.380497</td>\n",
       "      <td>-2.116291</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.877953</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>-2.826971</td>\n",
       "      <td>1.513363</td>\n",
       "      <td>1.886511</td>\n",
       "      <td>7.168218</td>\n",
       "      <td>0.884591</td>\n",
       "      <td>4.626950</td>\n",
       "      <td>-2.656402</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.093101</td>\n",
       "      <td>-1.274478</td>\n",
       "      <td>-1.255928</td>\n",
       "      <td>8.936292</td>\n",
       "      <td>-0.370502</td>\n",
       "      <td>3.281439</td>\n",
       "      <td>0.044154</td>\n",
       "      <td>0.909449</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.447425</td>\n",
       "      <td>-0.351174</td>\n",
       "      <td>-1.255928</td>\n",
       "      <td>4.312097</td>\n",
       "      <td>-0.679976</td>\n",
       "      <td>9.405648</td>\n",
       "      <td>0.584265</td>\n",
       "      <td>0.925197</td>\n",
       "      <td>0.539370</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    income    aspect  subscriptions  dist_healthy  save_rate  \\\n",
       "0        1 -0.607550 -0.664918      -0.208449      9.017895  -0.215764   \n",
       "1        2  0.338053 -0.207748       0.839031      7.766643   0.196869   \n",
       "2        3 -0.184205  1.127906      -0.208449      3.632069  -0.714362   \n",
       "3        4 -0.526467 -0.440815      -0.208449      5.372942  -0.542432   \n",
       "4        5 -2.851675  1.638861       1.886511      3.822477  -0.473660   \n",
       "...    ...       ...       ...            ...           ...        ...   \n",
       "1995  1996 -0.593504  1.414758      -0.208449      5.454545  -0.232957   \n",
       "1996  1997 -3.028085  1.011372       0.839031      3.632069  -0.473660   \n",
       "1997  1998 -2.826971  1.513363       1.886511      7.168218   0.884591   \n",
       "1998  1999  1.093101 -1.274478      -1.255928      8.936292  -0.370502   \n",
       "1999  2000  0.447425 -0.351174      -1.255928      4.312097  -0.679976   \n",
       "\n",
       "      dist_unhealthy       age  pop_dense  retail_dense  ...  area_c area_d  \\\n",
       "0          11.738935  0.854321   0.885827      0.492126  ...       1      0   \n",
       "1           6.805396  1.394432   0.874016      0.342520  ...       1      0   \n",
       "2          13.671772 -0.495957   0.944882      0.724409  ...       1      0   \n",
       "3           4.333286  1.124377   0.889764      0.444882  ...       1      0   \n",
       "4           5.967121 -2.116291   0.744094      0.661417  ...       0      1   \n",
       "...              ...       ...        ...           ...  ...     ...    ...   \n",
       "1995       14.013489 -1.306124   0.881890      0.744094  ...       1      0   \n",
       "1996        8.380497 -2.116291   0.944882      0.877953  ...       0      1   \n",
       "1997        4.626950 -2.656402   0.759843      0.744094  ...       0      1   \n",
       "1998        3.281439  0.044154   0.909449      0.598425  ...       1      0   \n",
       "1999        9.405648  0.584265   0.925197      0.539370  ...       1      0   \n",
       "\n",
       "        0    1    2    3    4    5    6    0  \n",
       "0     0.0  0.0  1.0  0.0  0.0  0.0  0.0  2.0  \n",
       "1     0.0  0.0  1.0  0.0  0.0  0.0  0.0  2.0  \n",
       "2     0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "3     0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "4     0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "1995  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1996  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1997  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1998  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1999  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[2000 rows x 57 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oosDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can clearly see that this is overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution to overfit is using L1/L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (accuracy): 0.62\n",
      "Fold #2\n",
      "Fold score (accuracy): 0.695\n",
      "Fold #3\n",
      "Fold score (accuracy): 0.68\n",
      "Fold #4\n",
      "Fold score (accuracy): 0.6375\n",
      "Fold #5\n",
      "Fold score (accuracy): 0.625\n",
      "Final score (accuracy): 0.6515\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Cross-validate\n",
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    #kernel_regularizer=regularizers.l2(0.01),\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=x.shape[1], \n",
    "            activation='relu',\n",
    "             activity_regularizer=regularizers.l1(1e-4))) # Hidden 1\n",
    "    model.add(Dense(25, activation='relu', \n",
    "                    activity_regularizer=regularizers.l1(1e-4))) # Hidden 2\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),verbose=0,epochs=500)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    pred = np.argmax(pred,axis=1) # raw probabilities to chosen class (highest probability)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure this fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) # For accuracy calculation\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_y_compare = np.argmax(oos_y,axis=1) # For accuracy calculation\n",
    "\n",
    "score = metrics.accuracy_score(oos_y_compare, oos_pred)\n",
    "print(f\"Final score (accuracy): {score}\")    \n",
    "    \n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout to overcome the problem of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (accuracy): 0.7039800995024875\n",
      "Fold #2\n",
      "Fold score (accuracy): 0.6666666666666666\n",
      "Fold #3\n",
      "Fold score (accuracy): 0.7256857855361596\n",
      "Fold #4\n",
      "Fold score (accuracy): 0.6959798994974874\n",
      "Fold #5\n",
      "Fold score (accuracy): 0.7002518891687658\n",
      "Final score (accuracy): 0.6985\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Cross-validate\n",
    "kf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(x,df['product']):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    #kernel_regularizer=regularizers.l2(0.01),\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(25, activation='relu', activity_regularizer=regularizers.l1(1e-4))) # Hidden 2\n",
    "    #model.add(Dropout(0.5)) # Usually do not add a dropout after final hidden layer\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),verbose=0,epochs=500)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    pred = np.argmax(pred,axis=1) # raw probabilities to chosen class (highest probability)\n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # Measure this fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) # For accuracy calculation\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_y_compare = np.argmax(oos_y,axis=1) # For accuracy calculation\n",
    "\n",
    "score = metrics.accuracy_score(oos_y_compare, oos_pred)\n",
    "print(f\"Final score (accuracy): {score}\")    \n",
    "    \n",
    "# Write the cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap: shuffle split for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for product\n",
    "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
    "df.drop('product', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('age').drop('id')\n",
    "x = df[x_columns].values\n",
    "y = df['age'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1: score=0.542110, mean score=0.542110, stdev=0.000000, epochs=126, mean epochs=126, time=19.135448455810547\n",
      "#2: score=0.829474, mean score=0.685792, stdev=0.143682, epochs=114, mean epochs=120, time=16.69512152671814\n",
      "#3: score=0.659827, mean score=0.677137, stdev=0.117953, epochs=150, mean epochs=130, time=22.770578622817993\n",
      "#4: score=0.634677, mean score=0.666522, stdev=0.103792, epochs=109, mean epochs=124, time=16.331239223480225\n",
      "#5: score=0.710136, mean score=0.675245, stdev=0.094459, epochs=81, mean epochs=116, time=12.585955142974854\n",
      "#6: score=0.867405, mean score=0.707272, stdev=0.112089, epochs=127, mean epochs=117, time=20.845578908920288\n",
      "#7: score=0.548239, mean score=0.684553, stdev=0.117754, epochs=121, mean epochs=118, time=21.773662090301514\n",
      "#8: score=0.473699, mean score=0.658196, stdev=0.130367, epochs=122, mean epochs=118, time=17.98751473426819\n",
      "#9: score=0.724164, mean score=0.665526, stdev=0.124647, epochs=101, mean epochs=116, time=15.780070543289185\n",
      "#10: score=0.985343, mean score=0.697508, stdev=0.152278, epochs=122, mean epochs=117, time=18.079370975494385\n",
      "#11: score=0.994696, mean score=0.724525, stdev=0.168463, epochs=92, mean epochs=115, time=14.390090227127075\n",
      "#12: score=0.612936, mean score=0.715226, stdev=0.164214, epochs=142, mean epochs=117, time=22.027668952941895\n",
      "#13: score=0.534108, mean score=0.701294, stdev=0.164988, epochs=119, mean epochs=117, time=17.904357194900513\n",
      "#14: score=1.102000, mean score=0.729915, stdev=0.189543, epochs=115, mean epochs=117, time=19.334694385528564\n",
      "#15: score=0.674483, mean score=0.726220, stdev=0.183637, epochs=101, mean epochs=116, time=15.569781064987183\n",
      "#16: score=0.898232, mean score=0.736971, stdev=0.182616, epochs=124, mean epochs=116, time=19.317705631256104\n",
      "#17: score=0.619069, mean score=0.730035, stdev=0.179322, epochs=130, mean epochs=117, time=20.792162895202637\n",
      "#18: score=1.033431, mean score=0.746891, stdev=0.187616, epochs=98, mean epochs=116, time=14.801248550415039\n",
      "#19: score=0.606018, mean score=0.739476, stdev=0.185301, epochs=155, mean epochs=118, time=23.61711025238037\n",
      "#20: score=0.721622, mean score=0.738584, stdev=0.180651, epochs=110, mean epochs=117, time=17.32031226158142\n",
      "#21: score=0.692421, mean score=0.736385, stdev=0.176572, epochs=117, mean epochs=117, time=20.32554030418396\n",
      "#22: score=0.656430, mean score=0.732751, stdev=0.173314, epochs=131, mean epochs=118, time=20.436548471450806\n",
      "#23: score=0.708742, mean score=0.731707, stdev=0.169575, epochs=121, mean epochs=118, time=19.02960991859436\n",
      "#24: score=0.593972, mean score=0.725968, stdev=0.168271, epochs=113, mean epochs=118, time=18.750704765319824\n",
      "#25: score=0.765744, mean score=0.727559, stdev=0.165055, epochs=105, mean epochs=117, time=16.53927183151245\n",
      "#26: score=0.746201, mean score=0.728276, stdev=0.161890, epochs=107, mean epochs=117, time=17.65149760246277\n",
      "#27: score=0.580449, mean score=0.722801, stdev=0.161298, epochs=114, mean epochs=117, time=18.446173906326294\n",
      "#28: score=0.639497, mean score=0.719826, stdev=0.159144, epochs=134, mean epochs=117, time=22.078674793243408\n",
      "#29: score=0.711428, mean score=0.719536, stdev=0.156384, epochs=108, mean epochs=117, time=19.04648733139038\n",
      "#30: score=0.575484, mean score=0.714735, stdev=0.155914, epochs=125, mean epochs=117, time=23.91087508201599\n",
      "#31: score=0.736005, mean score=0.715421, stdev=0.153425, epochs=109, mean epochs=117, time=24.138325929641724\n",
      "#32: score=0.587787, mean score=0.711432, stdev=0.152633, epochs=129, mean epochs=117, time=26.620893478393555\n",
      "#33: score=0.624156, mean score=0.708787, stdev=0.151045, epochs=143, mean epochs=118, time=31.024880409240723\n",
      "#34: score=1.155992, mean score=0.721941, stdev=0.166891, epochs=119, mean epochs=118, time=26.173672199249268\n",
      "#35: score=0.671128, mean score=0.720489, stdev=0.164708, epochs=99, mean epochs=118, time=23.484780311584473\n",
      "#36: score=0.527116, mean score=0.715117, stdev=0.165484, epochs=138, mean epochs=118, time=30.004273891448975\n",
      "#37: score=0.998083, mean score=0.722765, stdev=0.169559, epochs=96, mean epochs=118, time=19.94951343536377\n",
      "#38: score=0.748583, mean score=0.723444, stdev=0.167364, epochs=106, mean epochs=117, time=23.795368432998657\n",
      "#39: score=0.593915, mean score=0.720123, stdev=0.166468, epochs=120, mean epochs=117, time=27.258065700531006\n",
      "#40: score=0.592027, mean score=0.716921, stdev=0.165587, epochs=97, mean epochs=117, time=21.904661655426025\n",
      "#41: score=1.205477, mean score=0.728837, stdev=0.180083, epochs=83, mean epochs=116, time=18.86142611503601\n",
      "#42: score=0.568319, mean score=0.725015, stdev=0.179601, epochs=92, mean epochs=115, time=20.845580101013184\n",
      "#43: score=0.525588, mean score=0.720377, stdev=0.180027, epochs=130, mean epochs=116, time=29.78625798225403\n",
      "#44: score=0.649651, mean score=0.718770, stdev=0.178282, epochs=125, mean epochs=116, time=27.416076183319092\n",
      "#45: score=1.251712, mean score=0.730613, stdev=0.193001, epochs=98, mean epochs=115, time=19.80549931526184\n",
      "#46: score=0.560897, mean score=0.726923, stdev=0.192490, epochs=89, mean epochs=115, time=17.732346057891846\n",
      "#47: score=0.582584, mean score=0.723852, stdev=0.191566, epochs=137, mean epochs=115, time=27.20823907852173\n",
      "#48: score=0.628418, mean score=0.721864, stdev=0.190050, epochs=155, mean epochs=116, time=30.389304399490356\n",
      "#49: score=0.835848, mean score=0.724190, stdev=0.188790, epochs=100, mean epochs=116, time=20.410547494888306\n",
      "#50: score=0.487231, mean score=0.719451, stdev=0.189814, epochs=154, mean epochs=117, time=32.934494733810425\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "SPLITS = 50\n",
    "\n",
    "# Bootstrap\n",
    "boot = ShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=42)\n",
    "\n",
    "# Track progress\n",
    "mean_benchmark = []\n",
    "epochs_needed = []\n",
    "num = 0\n",
    "\n",
    "# Loop through samples\n",
    "for train, test in boot.split(x):\n",
    "    start_time = time.time()\n",
    "    num+=1\n",
    "\n",
    "    # Split train and test\n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "\n",
    "    # Construct neural network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=5, verbose=0, mode='auto', restore_best_weights=True)\n",
    "\n",
    "    # Train on the bootstrap sample\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    epochs = monitor.stopped_epoch\n",
    "    epochs_needed.append(epochs)\n",
    "    \n",
    "    # Predict on the out of boot (validation)\n",
    "    pred = model.predict(x_test)\n",
    "  \n",
    "    # Measure this bootstrap's log loss\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    mean_benchmark.append(score)\n",
    "    m1 = statistics.mean(mean_benchmark)\n",
    "    m2 = statistics.mean(epochs_needed)\n",
    "    mdev = statistics.pstdev(mean_benchmark)\n",
    "    \n",
    "    # Record this iteration\n",
    "    time_took = time.time() - start_time\n",
    "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f}, stdev={mdev:.6f}, epochs={epochs}, mean epochs={int(m2)}, time={time_took}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generate dummies for job\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generate dummies for area\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Missing values for income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standardize ranges\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convert to numpy - Classification\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Classification\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1: score=0.657763, mean score=0.657763, stdev=0.000000, epochs=86, mean epochs=86, time=21.059149980545044\n",
      "#2: score=0.648823, mean score=0.653293, stdev=0.004470, epochs=61, mean epochs=73, time=14.356209516525269\n",
      "#3: score=0.678740, mean score=0.661775, stdev=0.012539, epochs=45, mean epochs=64, time=11.071472644805908\n",
      "#4: score=0.650256, mean score=0.658896, stdev=0.011950, epochs=117, mean epochs=77, time=26.706393241882324\n",
      "#5: score=0.683478, mean score=0.663812, stdev=0.014523, epochs=50, mean epochs=71, time=12.252638101577759\n",
      "#6: score=0.684810, mean score=0.667312, stdev=0.015395, epochs=69, mean epochs=71, time=17.39631748199463\n",
      "#7: score=0.699848, mean score=0.671960, stdev=0.018242, epochs=72, mean epochs=71, time=17.19881844520569\n",
      "#8: score=0.747779, mean score=0.681437, stdev=0.030330, epochs=60, mean epochs=70, time=14.707688093185425\n",
      "#9: score=0.601582, mean score=0.672564, stdev=0.038046, epochs=89, mean epochs=72, time=19.43750500679016\n",
      "#10: score=0.661952, mean score=0.671503, stdev=0.036234, epochs=55, mean epochs=70, time=10.876023054122925\n",
      "#11: score=0.708204, mean score=0.674840, stdev=0.036123, epochs=58, mean epochs=69, time=9.966755390167236\n",
      "#12: score=0.743573, mean score=0.680567, stdev=0.039459, epochs=41, mean epochs=66, time=7.865205764770508\n",
      "#13: score=0.676315, mean score=0.680240, stdev=0.037928, epochs=97, mean epochs=69, time=15.791197299957275\n",
      "#14: score=0.707611, mean score=0.682195, stdev=0.037222, epochs=59, mean epochs=68, time=10.067248106002808\n",
      "#15: score=0.691348, mean score=0.682806, stdev=0.036032, epochs=54, mean epochs=67, time=9.20207667350769\n",
      "#16: score=0.733902, mean score=0.685999, stdev=0.037016, epochs=54, mean epochs=66, time=9.374805450439453\n",
      "#17: score=0.629595, mean score=0.682681, stdev=0.038284, epochs=83, mean epochs=67, time=13.687037229537964\n",
      "#18: score=0.597655, mean score=0.677957, stdev=0.041995, epochs=132, mean epochs=71, time=21.692703008651733\n",
      "#19: score=0.595818, mean score=0.673634, stdev=0.044801, epochs=46, mean epochs=69, time=8.168541193008423\n",
      "#20: score=0.717826, mean score=0.675844, stdev=0.044717, epochs=58, mean epochs=69, time=10.13616943359375\n",
      "#21: score=0.649219, mean score=0.674576, stdev=0.044006, epochs=63, mean epochs=69, time=10.787817478179932\n",
      "#22: score=0.744158, mean score=0.677739, stdev=0.045371, epochs=63, mean epochs=68, time=10.99383282661438\n",
      "#23: score=0.601019, mean score=0.674403, stdev=0.047051, epochs=66, mean epochs=68, time=11.120873928070068\n",
      "#24: score=0.693869, mean score=0.675214, stdev=0.046225, epochs=101, mean epochs=69, time=16.575772762298584\n",
      "#25: score=0.590358, mean score=0.671820, stdev=0.048247, epochs=62, mean epochs=69, time=11.175590515136719\n",
      "#26: score=0.683195, mean score=0.672258, stdev=0.047360, epochs=57, mean epochs=69, time=9.639755249023438\n",
      "#27: score=0.659231, mean score=0.671775, stdev=0.046540, epochs=80, mean epochs=69, time=13.405015707015991\n",
      "#28: score=0.720866, mean score=0.673528, stdev=0.046601, epochs=51, mean epochs=68, time=8.757663488388062\n",
      "#29: score=0.674578, mean score=0.673565, stdev=0.045791, epochs=50, mean epochs=68, time=8.615654468536377\n",
      "#30: score=0.735787, mean score=0.675639, stdev=0.046386, epochs=79, mean epochs=68, time=13.169007539749146\n",
      "#31: score=0.704120, mean score=0.676557, stdev=0.045908, epochs=58, mean epochs=68, time=10.556573629379272\n",
      "#32: score=0.654806, mean score=0.675878, stdev=0.045343, epochs=68, mean epochs=68, time=10.989354133605957\n",
      "#33: score=0.655664, mean score=0.675265, stdev=0.044785, epochs=56, mean epochs=67, time=8.966680526733398\n",
      "#34: score=0.569330, mean score=0.672149, stdev=0.047614, epochs=103, mean epochs=68, time=15.918206691741943\n",
      "#35: score=0.540240, mean score=0.668381, stdev=0.051819, epochs=75, mean epochs=69, time=11.923904180526733\n",
      "#36: score=0.641061, mean score=0.667622, stdev=0.051292, epochs=73, mean epochs=69, time=11.518872261047363\n",
      "#37: score=0.670787, mean score=0.667707, stdev=0.050596, epochs=51, mean epochs=68, time=8.328631162643433\n",
      "#38: score=0.697086, mean score=0.668480, stdev=0.050147, epochs=83, mean epochs=69, time=12.929980278015137\n",
      "#39: score=0.736493, mean score=0.670224, stdev=0.050654, epochs=71, mean epochs=69, time=11.487870931625366\n",
      "#40: score=0.728535, mean score=0.671682, stdev=0.050838, epochs=39, mean epochs=68, time=6.502492666244507\n",
      "#41: score=0.731257, mean score=0.673135, stdev=0.051049, epochs=46, mean epochs=67, time=7.52556586265564\n",
      "#42: score=0.638624, mean score=0.672313, stdev=0.050711, epochs=56, mean epochs=67, time=8.947677850723267\n",
      "#43: score=0.667009, mean score=0.672190, stdev=0.050124, epochs=70, mean epochs=67, time=10.978831768035889\n",
      "#44: score=0.767840, mean score=0.674364, stdev=0.051561, epochs=51, mean epochs=67, time=8.250625133514404\n",
      "#45: score=0.651325, mean score=0.673852, stdev=0.051098, epochs=70, mean epochs=67, time=11.244866132736206\n",
      "#46: score=0.664046, mean score=0.673639, stdev=0.050560, epochs=50, mean epochs=66, time=9.156426668167114\n",
      "#47: score=0.717828, mean score=0.674579, stdev=0.050424, epochs=45, mean epochs=66, time=7.909156322479248\n",
      "#48: score=0.753779, mean score=0.676229, stdev=0.051162, epochs=54, mean epochs=66, time=9.002686738967896\n",
      "#49: score=0.649887, mean score=0.675691, stdev=0.050774, epochs=85, mean epochs=66, time=13.909053564071655\n",
      "#50: score=0.668494, mean score=0.675547, stdev=0.050274, epochs=57, mean epochs=66, time=9.840745210647583\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "SPLITS = 50\n",
    "\n",
    "# Bootstrap\n",
    "boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=42)\n",
    "\n",
    "# Track progress\n",
    "mean_benchmark = []\n",
    "epochs_needed = []\n",
    "num = 0\n",
    "\n",
    "# Loop through samples\n",
    "for train, test in boot.split(x,df['product']):\n",
    "    start_time = time.time()\n",
    "    num+=1\n",
    "\n",
    "    # Split train and test\n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "\n",
    "    # Construct neural network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Hidden 1\n",
    "    model.add(Dense(25, activation='relu')) # Hidden 2\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Output\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=25, verbose=0, mode='auto', restore_best_weights=True)\n",
    "\n",
    "    # Train on the bootstrap sample\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    epochs = monitor.stopped_epoch\n",
    "    epochs_needed.append(epochs)\n",
    "    \n",
    "    # Predict on the out of boot (validation)\n",
    "    pred = model.predict(x_test)\n",
    "  \n",
    "    # Measure this bootstrap's log loss\n",
    "    y_compare = np.argmax(y_test,axis=1) # For log loss calculation\n",
    "    score = metrics.log_loss(y_compare, pred)\n",
    "    mean_benchmark.append(score)\n",
    "    m1 = statistics.mean(mean_benchmark)\n",
    "    m2 = statistics.mean(epochs_needed)\n",
    "    mdev = statistics.pstdev(mean_benchmark)\n",
    "    \n",
    "    # Record this iteration\n",
    "    time_took = time.time() - start_time\n",
    "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f}, stdev={mdev:.6f}, epochs={epochs}, mean epochs={int(m2)}, time={time_took}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
